\chapter{BACKGROUND}
\thispagestyle{plain}

\label{Background}

The purpose of this chapter is to provide necessary background information for understanding concepts related to the \framework.
In contrast to Chapter \ref{RelatedWork}, the previous research presented in this chapter do not share the same motivation as \fw, but provide a foundation upon which \fw builds.

\fw uses preexisting research in two major areas:
agent-based modeling and regression.
Section \ref{sec:abm} discusses what an ABM is, discusses some examples of ABMs, and lists some existing multi-agent software frameworks.
Section \ref{sec:reg} defines regression, outlines favorable and unfavorable properties, and describes a number of regression algorithms that have been incorporated into \fw.
%Finally, I discuss surface-to-surface intersection, which is used for solving the reverse-mapping problem.


\section{Agent-Based Modeling}
\label{sec:abm}
Agent-based models are computer simulations that are implemented from an agent perspective.
Agents in ABMs are typically \cite{epstein1999agent}:
\begin{itemize}
   \item bounded by a limited global view;
   \item only able to perform local interactions, affecting their local environment and neighboring agents;
   \item autonomous (i.e., there is no top-down control); and
   \item heterogeneous (i.e., agents within the system can have different properties) .
\end{itemize}
This paradigm stands in contrast to implementing the system from the ``observer" perspective, in which an overarching control system dictates what agents are to do.
For example, in NetLogo, an agent moves forward two units with the following command:
\begin{quote}
\texttt{\small > fd 2}
\end{quote}
Notice that this code is agnostic to the global direction of the agent or the position of the agent in the environment.
The code simply tells the agent to move forward two units.
In contrast, if this were to done from the observer perspective in NetLogo, the following code would be necessary:
\begin{quote}
\texttt{\small > set [xcor] of turtle 0\\
([xcor] of turtle 0 + 2 * cos([heading] of turtle 0))\\
> set [ycor] of turtle 0\\
([ycor] of turtle 0 + 2 * sin([heading] of turtle 0))}
\end{quote}
This code computes the change in the x-coordinate and the y-coordinate, given that the agent should move 2 units.
Then, it adds the result to the agent's original x- and y-coordinates.
Finally, it sets this turtle's x- and y-coordinates to the new x- and y-coordinates.
This process is cumbersome.
The agent-based property of models provides an intuitive way to build multi-agent systems.

One of the common uses of ABMs is to discover which local interactions generate a given emergent behavior of a system through experimentation.
The research question is posed well by Epstein as the \textit{Generativist's Question}:
\begin{quote}
   How could the decentralized local interactions of heterogeneous autonomous agents generate the given regularity?
\end{quote}
To answer this question, Epstein then poses the \textit{Generativist's Experiment}:
\begin{quote}
Situate an initial population of autonomous heterogeneous agents in a relevant spatial environment; allow them to interact according to simple local rules, and thereby generate---or ``grow"---the macroscopic regularity from the bottom up. \cite{epstein1999agent}
\end{quote}
If a model accurately generates the emergent behavior of the target system, then that ABM could provide a theory for why that behavior emerges.
Agent-based models are particularly well-suited to answer the Generativist's question.



Implementing systems as an ABM can be more natural than other approaches when the system cannot be defined in an aggregate manner or when individual behavior is complex \cite{bonabeau2002agent}.
ABMs are often compared to equation-based modeling (EBM), in which the model is a parameterized system of equations that describe system-level behavior (i.e., the observer perspective).
For example, a supply chain management system could be modeled as an ABM or an EBM \cite{parunak1998agent}.
In the ABM proposed by Parunak et al., individual agents represent different companies that trade with one another.
In contrast, the EBM is a series of ordinary differential equations describing the input and output of different components of the supply network.
The authors argue that in this situation, an ABM is more appropriate.

Modeling certain types of behavior, such as changes in state, erratic behavior and local interactions, can prove to be difficult with EBMs.
In the NetLogo example above where the agent moves forward, a relatively simple task of adjusting the position of an agent proved to be overly complicated.
When more detailed operations need to be performed, the complexity of the observer-perspective model increases dramatically.
Agent-based models remedy this difficulty by simply changing the context of the programming.


The concept of ABMs can be extended to other uses beyond modeling.
Many swarm intelligence techniques, such as particle swarm optimization \cite{kennedy1995pso} and ant colony optimization \cite{dorigo2004aco}, use a decentralized agent-based approach to solve optimization problems.
Although they are inspired by naturally occurring phenomena, their purpose is entirely separate from trying to realistically model a multi-agent system.

% Agent-Based Models
  % Agent perspective
  % Agents follow rules, or agent programs
  % low-level interactions emerge into interesting system-level properties



\subsection{Examples of Agent-Based Models}

ABMs have been used to model a variety of different systems.
In this subsection, I outline a number of agent-based models that have been developed by other researchers.
These examples will illustrate the uses for ABMs and how they can be used to answer research questions.

  % //Model// some real or artificial phenomena - abstract simulation - model pieces of interest
  % Uses: studying social animal behavior, studying human social interactions (traffic, disease propagation), supply chain management

\subsubsection{Reynolds Boid Flocking}

\begin{figure}[ht]
\centering
\includegraphics[scale=.66667]{images/netlogo_boidflock.png}
\caption{A boid flock moving through a two-dimensional space.}
\label{fig:netlogoboids}
\end{figure}

One of the first popular ABMs was the boid flock \cite{reynolds1987,reynolds1999sba}, in which agents move through an environment in a similar way to how birds flock.
A screen shot from NetLogo's boid implementation \cite{flocking} is shown in Figure \ref{fig:netlogoboids}.
Agents follow three simple rules:
   \begin{itemize}
      \item Move away from other agents to avoid collisions,
      \item Align to move in the same direction as nearby agents, and
      \item Move towards the central position of local flockmates.
   \end{itemize}
These simple agent-level behaviors result in the elegant flocking behavior observed in a top-down view of the system.
This system naturally lends itself to being implemented as an agent-based model because the agents act autonomously and have local interactions with only their neighbors.
The flocking behavior is emergent and would therefore be difficult to program directly (e.g., with equation-based modeling).

Boid flocking has been used in a number of applications, such as visualizing time-varying data \cite{1382896}, clustering documents \cite{cui2006flocking}, controlling unmanned air vehicles \cite{crowther2003flocking}, and art \cite{Boyd}.

Boids has remained one of my core inspirations for developing \fw.
The system is simple, yet exhibits a number of seemingly unpredictable system-level behaviors.

\subsubsection{Social Insect Behavior}

A number of different computational biology projects have aimed at modeling insect societies.
In modeling these systems, researchers are able to gain insights into how individual agent behaviors affect the system-wide emergent behavior.
These models are typically based on observations of the real insects.

An agent-based model approach has been used to model how army ants form traffic lanes \cite{couzin2003sol}.
The particular species of army ants discussed in this work forms two-way highways to reduce the number of head-on collisions while ants are searching for food and returning with food.
The authors show how the turning rates and perception of the individual ants affect the efficiency of the ants.
They found that when the turning rate is too high, ants are too willing to steer off course and intersect the path of other ants.
On the other hand, when the turning rate is too low, ants will not adjust their heading to avoid head on collisions.
By tuning their model to optimize highway performance, they reached an accurate model of the traffic flow in army ants.
The result of this research is an accurate model that describes the individual and group behavior of ants in a traffic situation.

With a different species of ants, researchers were able to produce an agent-based model that simulates the process of an ant colony that collectively selects a location for a new nest \cite{pratt2005agent}.
This process is interesting because an entire ant colony converges on one location, even though many of the ants have only scouted one nest site.
Agents are implemented as state machines, in which agents are either exploring for a site, assessing a site, canvassing a site, or committed to a site.
In each of these phases, the agent performs different actions and at any time may reject the current site and begin exploring again.
Over time, all ants converge on a single site as a nest.
With this model, the authors showed that a colony-level decision can be made by ants following agent-based rules.

An ABM has been developed to simulate swarming locusts \cite{buhl2006dom}.
Locusts have an interesting property in that when they are isolated, they tend to not stray from their current location.
However, when locusts are among several other locusts, they begin to ``march," travelling from one area to another, consuming everything in their path.
The authors were particularly interested in determining at what density the locusts  begin to march. By changing the number of simulated locusts in a confined space, they were able to determine the critical density at which they would march.
This simulation approach is far more practical than experimenting with real locusts.
The authors suggest that their models could be used to predict when locust swarms will occur to help warn farmers to protect their crops.

These particular studies in insect behavior illustrate the need for a system like \fw.
Researchers in this field are trying to build theories of how an agent's programming can affect system-level properties.
The authors perform empirical studies to answer their research questions and test their hypotheses.
However, this approach lacks a robust mathematical understanding of the behavior correlations.
Researchers would be able to answer their questions through analytical means provided by a domain-independent approach like \fw to reduce the amount of time spent tailoring specific experiments.
More on the comparison this particular type of ABM experimentation and the approach taken by \fw is provided in Section \ref{sec:abmexp}.

\subsection{Models of Human Societies}

Although human behavior is more complicated than insect behavior, local human interactions can often be generalized to build accurate models of a subset of human society.
Most such projects aim to create an accurate model of human interactions with each other in order to predict some society-level behavior.

Agent-based models have been used to determine how locals would react to an incident at the Pacific Missile Range Facility (PMRF) in Hawaii \cite{zanbaka}.
The researchers used census data to represent each islander as an individual agent that has either a positive sentiment or a negative sentiment towards the missile facility.
Each agents can change its sentiment towards PMRF either by interacting with another agent that has a different sentiment or by experiencing a local event.
The model simulates local events and agent interactions and displays how either positive or negative sentiment propagates accross the island.
With this model, the authors were able to model hypothetical situations and how they affect the sentiment on the island.

EpiSims is an agent-based simulation tool that models disease outbreaks \cite{eubank2004modelling}.
It uses estimates of how diseases are transmitted and how humans interact based on census and land-use data to realistically simulate human society.
The system simulates individuals going to work and shopping, which exposes them to the disease and exposes the disease to others.
With this system, researchers are able to predict the effectiveness of mass and targeted vaccination strategies, given a particular community.

STREETS is an agent-based model of pedestrian traffic \cite{schelhorn1999streets}.
Pedestrian traffic is affected by two major aspects: the layout of the street network and the location of attractions.
Instead of trying to analyze the behavior of the system from this data alone, STREETS simulates people to determine a number of properties of pedestrian traffic patterns.
STREETS initializes the system with a statistically accurate distribution of individuals across the environment.
Next, the agent-based model simulates the movement of agents from their arrival point to and through the urban center.
Agents visit buildings and attractions and walk among them.
Researchers use this tool to observe a top-level view that can be used to analyze the effectiveness of the urban center layout.
Hypothetical modifications to the environment can be performed in simulation to determine whether they would improve the traffic situation.

In these simulations, one of the main goals is to model human society so that hypothetical changes can be made to see the changes in the behavior of the system.
This way, the researchers do not have to use real humans in social experiments.
\fw could be helpful in answering this type of research problem.
A desired system-level property could be used to determine suitable configurations by solving the reverse-mapping problem.

  % To facilitate the creation of new agent-based models, many modeling environments have been developed... (give ~1 paragraph summaries of each)


\subsection{Multi-Agent Software Frameworks}
    % Swarm
Different implementations of different multi-agent systems have many similarities.
To reduce the amount of ``boiler plate" code for each new multi-agent system, a number of unique multi-agent software frameworks have been developed in the past two decades.
In this section, I survey the most popular of these framewworks.
\fw could be configured to analyze ABMs implemented in any of these frameworks.

\subsubsection{The Swarm Simulation System}
Swarm is one of the original agent-based modeling platforms, originally developed at the Santa Fe Institute in the 1990s.
Swarm is currently supported and hosted\footnote{The Swarm website: http://www.swarm.org/} by an independent organization called the Swarm Development Group.
The developers' motivation were to enable researchers to focus less on implementation and more on actual experimentation \cite{minar1996swarm}.
To achieve this goal, they implemented a number of libraries in Objective-C and Java that aid in the creation of ``swarm" objects, the building blocks of a Swarm simulation.
The swarm objects manage the agents and handle the time schedulers that queue the order of agent actions.
Also, agents can be nested as hierarchies in swarm objects to allow for heterogeneous collections of agents.
Swarm is a discrete time simulation, which means that time progresses as actions occur.

Unfortunately, programming in Swarm can require a significant amount of programming overhead, since the libraries are not a single integrated application \cite{kleinbreve}.
More recent software frameworks attempt to remedy this situation by providing a more cohesive library of tools.


\subsubsection{Repast}
The Recursive Porous Agent Simulation Toolkit (Repast) is a comprehensive agent-based modeling toolkit, focusing on modeling social interactions \cite{collier2003ref}.
The toolkit is freely available to download.\footnote{The Repast website: http://repast.sourceforge.net/}
Repast is fully object-oriented and attempts to be as platform-independent as possible, supporting programming in Java, Python, Visual Basic.Net, and more.

Repast's feature set is quite comprehensive and extensible. Repast's features are split into six modules \cite{north2006experiences}:
\begin{enumerate}
   \item The \textit{engine module} controls the agents, environment and scheduler.
   \item The \textit{logging module} records execution results.
   \item The \textit{interactive run module} manages user interaction with the model.
   \item The \textit{batch run module} allows the user to design a series of simulations to be executed in succession.
   \item The \textit{adaptive behaviors module} provides built-in adaptive agent behaviors that use techniques such as genetic algorithms and neural networks.
   \item The \textit{domains module} helps define environments, such as social systems, geographic information systems, and computational game theory.
\end{enumerate}
All these modules function together to provide a modular programming environment for a diverse set of multi-agent systems.
   
    % Repast
\subsubsection{Breve}
Breve is a unique 3D simulation environment that focuses on decentralized systems and artificial life \cite{kleinbreve}.
Like most other simulation environments, Breve is freely available.\footnote{Breve website:  http://www.spiderland.org/}
The authors of Breve tout that it aims to provide a platform for physically realistic 3D models.
The models simulate continuous time, and continuous space, unlike most other tool kits, which model time as discrete events and have grid world environments.
In addition, some physics models, such as gravity and object collision resolution with friction, are built-in features of every simulation.
Breve's OpenGL display engine allows for easy-to-implement 3D-accelerated graphics.
Users of Breve must use a custom object-oriented language called Steve.


One of the motivating applications for building Breve was Sims' (1994) evolved 3D creatures \cite{kleinbreve}.
In this project, creatures composed of several blocks and joints compete in a game to be closest to a ball.
The features of Breve naturally fit to this domain, since it has physically realistic servos and objects that can interact with one another.
Due to these features, Breve is an interesting system for modeling individual mobile agents, as well as multiple mobile agents.



\subsubsection{MASON}
    % MASON
MASON is a freely available multi-agent simulation toolkit developed at George Mason University.\footnote{MASON website: http://cs.gmu.edu/~eclab/projects/mason/}
MASON takes a different approach than previous multi-agent tool kits in that it strives to be minimalist and efficient for up to a million agents \cite{Luke}.
It is meant to be run on a number of back-end computation servers in parallel, without visualization.

MASON does not have any domain-dependent tools or built-in environments like Breve or Repast, leaving the user to implement their environments in Java.
Although MASON is quite minimalist, it is designed to be extensible so that it can be used as a foundation for new simulation systems.

MASON simulations can be interacted with using a separate visualization that binds to the simulation.
This is a different paradigm than other tool kits like NetLogo that are tightly coupled with the visualization.


\subsubsection{NetLogo}
    % Background information on NetLogo
NetLogo is a relatively new ABM system, which was started in 1999 at of Northwestern University as a derivative of StarLogo \cite{tisue2004netlogo}.
The software is free to download,\footnote{NetLogo website: http://ccl.northwestern.edu/netlogo/} but not open source.
As the name suggests, the language used by NetLogo is a derivative of Logo, a Lisp-like language.
An artifact of this language is that agents are referred to as ``turtles" in NetLogo.

NetLogo's language is tailored to the agent-based model paradigm.
Particularly, a program can change context to an individual and execute code from its point of view.
Also, populations of agents can execute these individual actions concurrently.
For example, the code to ask all the agents to move forward one unit, then turn right would be:
\begin{quote}\texttt{\small ask turtles [ fd 1 rt 90 ]}\end{quote}

Other than turtles, there is another built-in agent type: the ``patch."
Patches are organized as a grid in a two-dimensional environment to which agents are confined.
Users can interact with patches from their context, like the turtles.
Also, it is easy to retrieve turtles that are in contact with a patch and to retrieve which patch a turtle is on, from their respective contexts.
This makes turtle interactions with the environment simple to implement.

NetLogo also includes a built-in user interface and user interface editor.
The interface consists of controls, monitorsm and the domain visualization.
Users define controls that bind to global variables and buttons that bind to function calls.
In addition, users can add monitors and plots, which show a variable's value or plot a variable's value over time.
These are useful tools in conveying information that the domain visualization cannot.
NetLogo can be run ``headless" to facilitate parallel execution of models or to reduce run-time.

NetLogo comes with a number of extensions, most notably BehaviorSpace and HubNet.
BehaviorSpace is a tool for designing a series of systematic experiments with different system configuration parameters.
BehaviorSpace performs a user-defined measurement value after each individual execution and reports the result to a data set in the form of a spreadsheet.
HubNet is a server/client tool that allows several users of a system to interact with a NetLogo ABM at the same time, which is useful for classroom instruction.

NetLogo can be interacted with from an external Java API.
A NetLogo ``workspace" is instantiated as an object and can be used to send commands and to query current variable values.
This capability is useful for an number of tasks.
First, sometimes NetLogo's language is not expressive enough and some may find programming in Java more familiar.
In addition, external Java libraries (such as machine learning libraries) can be used without modification by integrating with NetLogo from its Java API.
Also, a sequential experiment system can be implemented in Java if a user would like to run experiments without BehaviorSpace.

An extensive model library with over 140 sample models is bundled with the NetLogo distribution.
These already existing models serve as excellent examples for new models as well as starting points for modified models.
Most of the domains discussed later in this dissertation are from this model library.

NetLogo is my ABM system of choice for this dissertation research for a number of reasons.
First, NetLogo's learning curve is surprisingly short.
From personal experience, an experienced programmer can learn to write a domain similar to the Wolf Sheep Predation model in less than an hour.
In addition, the documentation\footnote{The NetLogo documentation is available at http://ccl.northwestern.edu/netlogo/docs/} is well organized and detailed.
Second, the model library provides several models that are interesting and easy to work with.
Since each of these models are implemented in NetLogo, I was able to implement \fw so that it interacts with each ABM in a similar way.
Other multi-agent system toolkits provide more flexibility in implementation, which would make identifying agent-level control parameters and system-level properties more difficult.
Third, although NetLogo's platform is well contained, the interactions possible with the Java API make almost anything possible.
I was able to implement my framework as an external modular application that interfaces with NetLogo, instead of as a built-in system-dependent tool.
This property makes my research easily extensible to other ABM systems in the future.

  % NetLogo - used by this research
    % Concept - based off logo, 2d domain of patches, agents are ''turtles''
    % Agents are asked to perform actions from their context. e.g., ask turtles [ fd 1 ]
    % Plotting and monitors
    % BehaviorSpace extension for sampling
    % Java APIs


\section{Regression}\label{sec:reg}
Regression is an integral part of this dissertation research, as it provides the foundation for solving the forward- and reverse-mapping problems.
  % The reason for regression: we have independent and independent real-valued variables.
Regression techniques are used to predict values of dependent variables, given values of the independent variables.
The typical approach is to use a model developed from a sample training set to infer new values that of configurations that have not been sampled.
Also, regression can be used to smooth the natural error in sampling.

Linear regression is perhaps the simplest form of regression. It fits a line to represent the correlation between one independent variable and one dependent variable, taking the form of:
\[\mathrm{y} = \mathrm{x} + b.\]
There exists a closed-form solution to determine $m$ and $b$ in order to minimize the sum of squares between the training data and the curve.

Unfortunately, linear regression is limited in that it only models linear relationships, and is not able to model nonlinear ones, such as rhythmic oscillations or quadratic correlations.
Two paths are generally taken to address this concern.
The first is to use the kernel trick \cite{muller2001introduction} to map nonlinear data to be linear, but higher-dimensional.
Then, once the data is projected into a space in which it is linear, linear methods (e.g., linear regression, perceptrons \cite{minsky19882perceptrons}, or support vector regression \cite{smola2004tsv}) can be used.

% Regression
   % Give definition of the regression problem
The second approach is to use nonlinear methods, which relax linear regression to learning a function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ that satisfies the following equality:
\[y_i = f(\mathbf x_i) + \varepsilon_i.\]
In this equation, $y_i$ is a dependent variable and $\mathbf x_i$ is the vector of independent variables associated with $y_i$.
Also, there is an assumption of some normally distributed and independent error with each point, denoted by $\varepsilon_i$.
The process of \textit{nonparametric} regression is to estimate this function directly \cite{fox2002r}.

Alternatively, a \textit{parametric} regression model keeps the form of the function $f(\cdot)$ fixed, but changes parameters to this function, instead.
Instead of learning $f(\cdot)$ directly, a vector of model parameters $\mathbf \beta$ are optimized to fit the data \cite{fox2002r}:
\[y_i = f(\mathbf \beta, \mathbf x) + \varepsilon_i.\]
For example, $f(\cdot)$ could model two-dimensional sinusoidal data with the model:
\[f(\mathbf \beta, (x_1, x_2)) = \beta_1 + \beta_2 \sin (x_1 - \beta_3) + \beta_4 \sin (x_2 - \beta_5)\]
Typically, the value of the least squares metric is minimized to fit the curve to the data.

  % What I need in a regression algorithm: can model nonlinear behaviors that are difficult to apply a model to and works in many dimensions; needs to build relatively smooth models for the inverted regression to be smooth.
While developing the \framework, I needed regression algorithms that satisfied a number of properties.
The regression algorithm should scale well with dimensionality, since agent-based model behavior spaces (i.e., the space of agent-level parameters and system-level properties) are typically high-dimensional.
I also needed algorithms that could model nonlinear correlations, since behavior spaces are diverse and rarely maintain linearity throughout the entire space.
However, in the ABMs I have experimented with, all spaces are very smooth locally.
That is, there is little variance in values between nearby locations in the behavior space.
Even in the situation where there is variance, the error is typically evenly distributed and cancels out if the same configuration is sampled a number of times.
Therefore, nonlinear parametric regression can fit to the overall behavior space, without having to worry about fine-grained variations in the data.
Also, the mappings built by the regression models should be smooth.
This smoothness property is important for the tractability of finding the reverse mapping, since bumpy surfaces will naturally yield more intersections than smooth ones.
Therefore, regression methods that smooth the data, such as LOESS, are effective in this situation.

In the course of testing \fw, I used three regression techniques: k-nearest neighbor, LOESS, least-squares nonlinear regression.

  % Figure of Fires domain, boids domain, wolf/sheep predation domain behavior graphs
  % So far, I have implemented the following regression algorithms to work with \fw: K-Nearest Neighbor, LOESS (Locally weighted scatterplot smoothing, least-squares Non-Linear Regression, Multilinear Interpolation
\subsection{K-Nearest Neighbor Regression}
  % K-Nearest Neighbor Regression
    % Concept - Take k-nearest neighbors and average them
K-nearest neighbor (KNN), in general, is the process of selecting the $k$ nearest points to some point $\mathbf x$.
These points can then be used for classification or regression.
In the simplest case, each neighbor's $y$ value is averaged to infer a value $\hat y$ for the given point $\mathbf x$.
KNN is easy to implement and accurate with large data sets.
The accuracy of this regression can be improved by weighting points by distance or by using a secondary regression algorithm (e.g., linear regression) on the neighbors.

    % The role of KNN - easy to implement, accurate with large data sets
We use KNN in our results as a baseline, since it is easy to implement and accurate.
In addition, it is nonparametric, which makes it agnostic to the shape of the behavior space.
Therefore, KNN requires little to no configuration or tailoring to a particular domain.

    % Slow with large data sets because of all the distance calculations needed.
      % Can be sped up with advanced nearest neighbor search, such as a kd-tree or local sensitivity hashing.
However, when implemented naively, the running-time scales linearly with the size of the data set because the process of finding the nearest neighbors requires a scan of all data points.
This search time can be reduced with the implementation of faster searching techniques, such as locality-sensitive hashing \cite{gionis1999similarity}, among other methods.
Even with faster neighbor-locating techniques, some sort of search is required for each query to KNN.

Selecting $k$ is an important step, as different values of $k$ will fit the data better than others.
If $k$ is too low, the regression will be overfit since it is ignoring many of the points.
If $k$ is too large, the regression will be overgeneralized and provide a mapping that is too smooth.
Unfortunately, the nature of the data and the size of the data set determine which $k$ is best.
To determine a proper $k$, I use the standard technique of using 10-fold validation to determine which in a set of candidate $k$ values results in the least average error.

The spaces generated by KNN are not continuous (particularly if the neighbors are not weighted).
This is because similar points will have the same neighbors and, in effect, have the same predicted value.
There are inflection points one side of where the k-nearest neighbors will include a particular data point, whereas on the other side it will not.
At this separation, there will be a discontinuity in predicted values.
This can be a problem for solving the reverse-mapping problem because the intersection between hyperplanes generated by KNN will not intersect smoothly.
This can be remedied by using KNN in conjunction with multilinear interpolation.
      
\subsection{Robust Locally Weighted Regression and Smoothing Scatterplots (LOESS)}


    % Advantages: nonparametric (useful for my domains), 
    % Role in \fw : accurate and nonparametric. Conceptually, if we sample infinitely with LOESS, we will get a very smooth graph (which makes it nice for inverted regression).
Robust Locally Weighted Regression and Smoothing Scatterplots (LOESS) is a mature nonparametric regression technique for fitting curves to data   \cite{cleveland1979robust,cleveland1988locally}.
Similar to k-nearest neighbor, LOESS uses local points to infer values of new data points.
LOESS also iteratively smooths the regression curve, allowing for variable magnitudes of smoothing.
This is important for particularly noisy data sets.
The role of LOESS in the testing of \fw is that it is more robust than KNN, yet still nonparametric.

    % Concept - take some subset of neighbors, weight them, and then perform linear regression on them
Abstractly, LOESS fits a new $\hat y_i$ to every $\mathbf x_i$ to replace the original noisy $y_i$.
Then, LOESS iteratively smooths each $\hat y_i$ to reduce variability.
Specifically, LOESS follows the following steps:
\begin{enumerate}
   \item Initialization step -- For each $\mathbf x_i$, weight all other points $x_j$, where $j = 1...n$, based on a weighting function $W(\mathbf x_i, \mathbf x_j)$. which weights closer points higher. Perform weighted linear regression to infer $\hat y_i$.
   \item Smoothing step -- For each $\mathbf x_i$, weight all other points based on $w_i$, as well as a new weight function $\delta$, which returns a magnitude inversely proportional to $y_i - \hat y_i$ (i.e., the larger the distance, the lesser the weight). Perform weighted linear regression to infer $\hat y_i'$.
   \item Set each $\hat y_i$ to $\hat y_i'$.
   \item Repeat the the smoothing step as many times as necessary.
\end{enumerate}
Values in between $\mathbf x$s can be now be interpolated.

    % Role of the smoothing parameter -- how much data is used to fit each polynomial
LOESS can be customized in a number of ways.
The different weighting functions can be changed to change the amount of influence that other points have on the linear regression step.
Typically, these weighting functions have a ``smoothing" parameter, which increases the influence of further away points, effectively reducing the strong influence of local points.
Adjusting the smoothing parameter is important because if it is too low, the regression curve will be erratic (i.e., overfit), whereas, if the smoothing parameter is too high, some features of the curve may be eliminated.

  % LOESS
    % Weight function weights points by distance -- most common function is the tri-cube function
LOESS is computationally expensive in comparison to other approaches,
because weights are applied and points are readjusted iteratively a number of times.
However, the model can be built offline and then stored.
Once the $\hat y_i$ values are inferred, they can be used to interpolate new points (similar to multilinear regression) in response to queries.
Caching these values provides a quick response time to users wanting to infer $\hat y$ values.
This property satisfies one of the design criteria of \fw: the regression algorithm should be fast for the user.


\subsection{Nonlinear Regression}

Nonlinear regression (NLR) is a parametric approach to regression.
  % NonLinear Regression
    % Concept - take a model of the data, optimize the parameters to minimize least squares.
In this approach, a parametric model is provided by the user that represents the relationships in the data, in general.
This is typically done based on some sort of intuition provided by the user.
For example, the data may appear sinusoidal or quadratic, in which case a model involving sine curves or quadratic polynomials, respectively, would be appropriate.
    % Accuracy is largely dependent on the model
Similarly to how linear regression will not model nonlinear relationships well, certain nonlinear models will not model other nonlinear relationships.
Therefore, accuracy is largely dependent on the selection of the correct model.

Optimization techniques, such as Gauss-Newton or Levenberg-Marquardt \cite{mor1977levenberg}, are used to adjust nonlinear model parameters in order to minimize the least squares metric \cite{gallant1975nonlinear}.
These processes iteratively move models towards the best fit to the data.

Nonlinear regression is of particular interest in my research because it is analytically invertible, since trained NLR models are already in the form of a function.
Unfortunately, since NLR is parametric, it requires a significant amount of configuration for each target domain.

