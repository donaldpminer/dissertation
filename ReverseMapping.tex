\chapter{THE REVERSE MAPPING PROBLEM}
\thispagestyle{plain}

\label{ReverseMapping}

The reverse-mapping problem is the problem of defining a function $f^{-1}$ that maps a system-level configuration $\mathbf y$ onto a solution space $\hat{\mathbf S}$ that represents all possible configurations that would have the system exhibit $\mathbf y$:
   \[ f^{-1}(\mathbf y) \rightarrow \hat{\mathbf S}. \]
Every configuration $\hat {\mathbf x} \in \hat {\mathbf S}$ should satisfy the constraint $f(\hat{\mathbf x}) \approx \mathbf y$, where $f$ is the forward mapping.
That is, $\hat{\mathbf S}$ contains all the points that would predict $\mathbf y$ in the forward mapping.

This method of developing a reverse mapping is compared to optimization.
Finding a set of configuration parameters that satisfies a system-level property, by definition, is an optimization problem.
However, instead of just a single point being returned, a reverse mapping returns the space of all points that would satisfy the configuration.
This has a number of benefits, such as being able to visualize and inspect the entire solution space.
Analysis of how the solution space changes in respect to the configuration parameters can be performed.
Different solutions that produce similar results can be selected from a number of good solutions based on some exterior preference on points.
That is, although all points in a solution space should be satisfactory, some points may be more desirable for a number of reasons, such as points which have less expected variance.

In this chapter, I give details of how \fw approaches the solution to this problem, in general, then delves deeper into actual implementation of the solution.
Then, I discuss evaluation criteria for implementations of reverse-mapping problem solutions.
Throughout this chapter, I use the NetLogo Fires ABM\footnote{More on the Fires model is discussed in Section \ref{sec:Fires}} as an example.
The Fires domain is simple and has solution spaces that are easy to visualize.
Other domains, such as Wolf Sheep Predation, have too many dimensions to make graphing feasible.
The arguments made with the aid of the Fires domain scale to larger dimensions.



\section{The \fw Approach: Simplical Complex Inversion}

In abstract terms, the \fw reverse-mapping solver approach, named \textit{Simplical Complex Inversion} (SCI), builds an invertible approximation of the forward mapping, since often times the regression approach used is not easily invertible.
I have found that inverting even the simplest approaches such as K-nearest neighbor and LOESS are either difficult to implement or computationally expensive.
By approximating a representation of the forward mapping that is invertible, solving the reverse-mapping problem becomes computationally tractable.
The process of inverting a method directly is covered in later in this chapter, in Subsection \ref{subsec:funcinvert}.
These approaches are generally not preferred over other approaches since they are dependent on the forward mapping approach used.
Meanwhile, SCI is applicable to any forward-mapping technique.

Much like the forward-mapping solution, $\mathbf y$ is split into subspaces to simplify the problem:
\[ \mathbf y = \{y_0, y_1, \ldots, y_{|\mathbf y|}\}. \]
The solution space is split up in a similar manner:
\[ \hat{\mathbf S} = \{\hat S_0, \hat S_1, \ldots, \hat S_{|\mathbf S|}\}. \]
By performing this split, each forward mapping can be inverted independently:
\[ f^{-1}_i(y_i) \rightarrow \hat S_i. \]

Recombining the individual $\hat S_i$ into $\hat{\mathbf S}$ is not as simple as recombining individual $\hat y_i$ into $\hat{\mathbf y}$ in the forward-mapping solution.
Since each solution space represents which configurations satisfy a particular system-level requirement, the solution space $\hat{\mathbf S}$ is the intersection of all these spaces:
\[ \hat{\mathbf S} = \hat S_0 \cap \hat S_1 \cap \ldots \cap \hat S_{|\mathbf S|}.\]
All points at the intersection of these spaces should satisfy all system-level properties at once.

Simplical Complex Inversion has three phases.
First, regression is used to infer the system-level property values for several ``knots" in the configuration space.
The location of these knots are used to segregate the configuration space into a number of simplexes (multi-dimensional triangles).
This segregated configuration space is referred to as a \textit{simplical complex}.
Next, the intersection between each of these simplexes and a plane representing the target system-level property is found.
That is, SCI finds the equation of the hyperplane through each simplex that satisfies the target system-level property
A curve representing the configurations that would satisfy the target system-level property is pieced together from all the intersections found.
This subsection discusses these steps in detail along with Figure \ref{fig:ISFlow}, which illustrates the SCI process.

\begin{figure}[ht]
\centering
\includegraphics[scale=1]{images/ISflow.pdf}
\caption{The flow of stages in the Simplical Complex Inversion approach to the reverse-mapping problem in a two-dimensional configuration space.}
\label{fig:ISFlow}
\end{figure}

I claim that SCI is a general approach to the reverse-mapping problem that is applicable in all domains in which the forward-mapping problem is solved accurately.
Also, SCI provides the most useful information than optimization, since SCI returns a piecewise and continuous set of hyperplanes.
These hyperplanes give a more continuous and complete view of the nature of a specific system-level property value.




\begin{figure}[ht]
\centering
\includegraphics[scale=.66666667]{images/rii0.pdf}
\caption{The raw data set, containing 120 points, from the Fires domain.}
\label{fig:rii0}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[scale=.66666667]{images/rii1.pdf}
\caption{Linear interpolation performed on the raw data set (see Figure \ref{fig:rii0}) from the Fires domain.}
\label{fig:rii1}
\end{figure}

\subsection{Segregating the Configuration Space}
The reason for using regression as the first step is that the raw data in many ABMs will exhibit variance.
For example, raw data from the Fires ABM is shown in Figure \ref{fig:rii0}.
If this data were to be used with interpolation, the curve for the behavior space would be very erratic.
This is a problem for SCI because erratic curves will result in a number of inaccurate intersections.
A linear interpolation performed on the raw Fires data to generate a behavior space curve is shown in Figure \ref{fig:rii1}.
From this figure, the curve appears very erratic and would provide poor results with SCI.


The behavior space is naturally much smoother when mapped to the regression space.
The first step of SCI is to use the forward mapping (i.e., regression) to infer knots in the space.
These knots canvas the space and provide reference points for the interpolation.
To generate these points, the forward mapping is queried by passing a configuration parameter.
An inferred system-level property value is returned.
The data knot in an $n$-dimensional\footnote{$n$ refers to the dimensionality of the configuration space for the rest of this chapter.}  configuration space is the configuration space parameter values ($x_k$) and the system-level property value ($y$):
\[(x_1, x_2, ..., x_n, y).\]

The configuration space is then segregated with Delaunay triangulation  into adjacent simplexes (simplical complex).
These simplexes have $n + 1$ corners (e.g., triangles if $n=2$ and lines if $n=1$) and spans $(n+1)$-dimensional space.
Note that the behavior space resides in $(n+1)$-dimensional space, but the simplexes are $n$-dimensional objects (e.g., a tetrahedron in four-dimensional space if $n=3$ space or a line segment in two-dimensional space if $n=1$).
This is because the system-level property $y$ is not taken into consideration for the the Delaunary triangulation.
The relationships between these objects' dimensionality and different dimensional configuration spaces are outlined in Table \ref{table:dims}.
For example, in the Fires ABM (1-dimensional configuration space), the space is segregated into line segments that reside in two-dimensional space.

\begin{table}[ht]
  \caption{Dimensionality of Objects for Simplex Inversion}
  \centering
  \begin{tabular}{c c c c}
    \hline \hline
    Configuration Space & Behavior Space & Simplex & Intersection \\
    Dimensionality      & Dimensionality &         &  \\
    \hline
    1 & 2 & line & point \\
    2 & 3 & triangle & line \\
    3 & 4 & tetrahedron & plane \\
    4 & 5 & pentachoron & 3D hyperplane \\
    5 & 6 & 5-simplex & 4D hyperplane \\
    $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
    $n$ & $n + 1$ & $n$-simplex & ($n-1$)D hyperplane \\
    \hline
  \end{tabular}
  \label{table:dims}
\end{table}

Delaunay triangulation is used to segregate the space.
If the configuration points were randomly scattered, a standard algorithm for computing the Delaunay triangulation could be used.
However, since SCI controls how configuration points are distributed, it can organize the points in such a way where a solution to the Delaunay triangulation can be computed implicitly.
In general, SCI will evenly space the sample points as a grid and split each hypercube into two simplexes.
The Delaunay triangulation is easy to compute with points organized in this way.
For example, in Figure \ref{fig:ISFlow}, the space is segregated into a number of adjacent triangles that satisfy the requirements for being a Delaunay triangulation.

The equations of the simplexes can be defined in terms of the hyperplane in which they reside.
The $n+1$ points define a $n$-dimensional hyperplane.
If a point is within all the facets and lies on the hyperplane, the point is on the simplex.
For example, in the Fires ABM, the two points defining a line segment reside on a more general line.
Meanwhile, the facets are defined by the points individually.
If a behavior space point lies on th line and resides between the two facet points, the point is a realistic point.
This explanation expands to two-dimensional configuration spaces, which has triangles as simplexes and line segments are facets.
If a point lies on the plane defined by the 3 points, and is within the boundaries of the line segment facets, the point is realistic.


\begin{figure}[ht]
\centering
\includegraphics[scale=1]{images/simint.pdf}
\caption{A triangle from a two-dimensional configuration space (left) and a tetrahedron from a three-dimensional configuration space (right) are intersected with the plane $y=5.5$. The $y$-values for each corner are given.}
\label{fig:simint}
\end{figure}

\subsection{Simplex Intersection}
Recall that the final goal of this process is to find the equation of the intersection between all the simplexes and a system-level property hyperplane.
Therefore, no complicated technique needs to be performed to calculate the actual equation of the simplex or the facets.
Instead, the intersection at the edges is found by finding the intersections with the edges.
These edge intersections are then used to construct the intersection through the simplex.
The process to find the intersection between the system-level property hyperplane and a simplex is as follows:
\begin{enumerate}
   \item Pair off each corner with every other corner, in every possible combination. These point pairs define the edges of the simplex.
   \item Determine which edges intersect with the hyperplane. An edge intersects with the hyperplane if the target system-level property value  is between the $y$-values for the two points that define the edge. From the intermediate-value theorem, the plane must intersect with this line segment at some point, at least once.
   \item Use linear interpolation to determine at which point on the edge line segment the intersection occurs. For example, consider the corners have $y$-values of 2 and 4 and the target system-level property value is 3---the location of the intersection is halfway between these points.
   \item The set of all edge intersection points lie on the hyperplane that intersects the simplex.
\end{enumerate}
This approach totally circumvents the need for modeling the actual simplexes as equations, which can be challenging to implement.
Two illustrative examples of this intersection method being used are shown in Figure \ref{fig:simint}.
In the example on the right-hand side in Figure \ref{fig:simint}, the two-dimensional plane intersects the tetrahedron in four places.
However, only three of these points are needed to define the plane because the fourth point is coplanar and thus redundant.
This illustrates the fact that not every edge has to be checked for intersection, only enough points to define the intersecting hyperplane.
Since the intersecting hyperplane is $(n-1)$D, $n$ points are needed.
SCI uses the following standard representation for a plane, where $\mathbf C$ is a vector of constants and $\mathbf x$ is the vector of configuration parameters and system-level property:
\[\mathbf C \cdot \mathbf x + D = 0\]
\[C_0 x_0 + C_1 x_0 + ... + C_n x_n + C_{n+1} x_{n+1} + D = 0. \]

This approach is very general and will work in most cases, however, when the plane intersects with either a corner point or an edge only, no plane can be defined because not enough non-colinear points can be found.
To circumvent this problem, SCI considers the boundaries of the simplex as not part of the simplex.
Thus, a point that intersects with only the corner or an edge will not be considered in the final piecewise intersection.

\subsection{Recombination of Solution Spaces}

Once solution spaces have been found for each of the desired system-level properties, they must be recombined into one solution space.
This final solution space will consist of points that exhibit the specified system-level property values, or perhaps none at all.
The spaces generated by SCI are in the form of hyperplane.
Therefore, the recombination is the intersection of all these hyperplanes.


\begin{figure}[ht]
\centering
\includegraphics[scale=1]{images/intcheck.pdf}
\caption{Illustration of two recombination scenarios: intersecting (left) and not intersecting (right).}
\label{fig:intcheck}
\end{figure}


First, SCI verifies if the hyperplanes intersect within the simplex.
Two hyperplanes intersect if the points on one hyperplane are separated by the other hyperplane.
If the points are separated, then there must be an intersection.
An illustration of points being separated by a hyperplane, and not, is shown in Figure \ref{fig:intcheck}.
The points used for the hyperplanes are the edge intersections, therefore, the two planes must intersect within the simplex.
This check is performed by plugging in values for the edge intersections of one hyperplane into the other hyperplane.
Then, the nature of the inequality (greater-than or less-than) specifies which side the edge intersection is on.
This calculation is easy to perform since SCI has the edge intersection points and the equation of the hyperplanes already computed.
Also, this process can be repeated for any number of hyperplanes by performing this test for each possible pair of hyperplanes.
However, it may be the case that the hyperplanes do not intersect in the same places, although all hyperplanes intersect, pairwise.


To find the intersection, a system of linear equations is set up in matrix form:
\[  \left[ \begin{array}{ccccc}
C_{0,0} & C_{0, 1} & ... & C_{0,n+1} & D_0 \\
C_{1,0} & C_{1, 1} & ... & C_{1,n+1} & D_1 \\
\vdots  & \vdots   & \vdots & \vdots & \vdots \\
C_{m,0} & C_{m, 1} & ... & C_{m, n+1} & D_m \end{array} \right]
\left[ \begin{array}{c}
x_0 \\
x_1 \\
\vdots \\
x_{n+1} \end{array} \right] = \mathbf 0
\] 
To solve this system of equations, SCI reduces the coefficient matrix to reduced row echelon form (RREF).
What remains is a system of reduced linear equations that are more concise in defining the intersection.
From the check performed as the first step, any intersectios returned by the solution of this system of equations is guaranteed to be within the simplex.


The RREF can reveal that the system is either overspecified or underspecified.
A system of equations is overspecified if there is a row in RREF that is all zeros, except for the last column value $D \neq 0$:
\[ \left[ \begin{array}{ccccc} 0 & 0 & ... & 0 & D \end{array} \right]. \]
This row translates to $0 = D$, which is not true.
That is, there is no possible configuration of $\mathbf x$ that will satisfy this specific equation.
Thus, the set of system-level properties the user has provided is not able to be created with this ABM.
This is typical if the user has specified too many requirements of the system-level properties.
In this case, the user should remove some less important system-level property requirements and allow the system to suggest values for them.

RREF reveals that the system is underspecified if there are any rows with multiple non-zero values in it, other than $D$. For example, consider the row pulled from a matrix in RREF:
\[ \left[ \begin{array}{ccccc} 0 & 1 & 2 & 0 & 5 \end{array} \right]. \]
This row translates to $x_1 + 2x_2 = 5$.
Therefore, $x_1$ and $x_2$ are free variables, but are still constrained by this equation.
An infinite number of solutions can satisfy the system-level properties in this case.
This is not a problem like being overspecified, since there are a number of possible solutions at the disposable of the user.


\subsection{Granularity}

SCI can be configured by adjusting the granularity of the knots.
SCI approximates an invertible continuous representation of the forward-mapping.
Therefore, as the granularity of SCI increases, it models the forward mapping more accurately, \textit{not} the original target domain.
Thus, the granularity should be as high as computationally acceptable.

The effect of the granularity on accuracy is dependent on the nature of the forward-mapping regression method used.
If the forward-mapping produces overfit or otherwise inaccurate predictions, the reverse-mapping produces will be inaccurate as well when it comes to suggesting behavior for the target domain.
This difficulty should be dealt with in the forward-mapping solving step, not the reverse-mapping solving step.
This is because the purpose of SCI is to model the forward-mapping, not the domain.

An empirical analysis of the relationship between granularity and accuracy is provided in Chapter \ref{Results}.
The accuracy is measured as the difference between the continuous forward-mapping function


\subsection{Example: Fires ABM}

Figure \ref{fig:rii} illustrates the progression of SCI from step to step when used for the Fires ABM.
First, the forward-mapping problem is solved, with whichever regression method.
Then, the knots are formed in evenly spaced intervals: in this case intervals of 1\% (see top right image in Figure \ref{fig:rii}).
The simplexes in the case of the Fires ABM are line segments, since the configuration space is one-dimensional.
Therefore, linear interpolation between the points produces these simplexes (see bottom left image in Figure \ref{fig:rii}).
This one segment is also the only edge of the simplex.

\begin{figure}[ht]
\centering
\includegraphics[scale=.5]{images/rii0.pdf}
\includegraphics[scale=.5]{images/rii2.pdf}
\includegraphics[scale=.5]{images/rii3.pdf}
\includegraphics[scale=.5]{images/rii5.pdf}
\caption{The progression of SCI in the Fires ABM from raw data set (top left), to intersection (bottom right). }
\label{fig:rii}
\end{figure}

Next, SCI finds the intersection between the behavior space and a desired system-level property behavior $b = Burned~{ }Trees / Total~{ }Trees = 0.9$ (see bottom right image in Figure \ref{fig:rii}).
This is done by checking each simplex to see if $0.9$ is within the range of the minimum value and maximum value for $b$ in each simplex.
The only segment that intersects the $0.9$ plane is the one between 63\% and 64\%.
The intersection between this segment and the line is calculated, which in this case is approximately at $Density = 63.1$\%.

Therefore, setting $Density = 63.1$\% will be expected to yield 90\% of the trees burned down.
In higher dimensional domains, the number of points that will satisfy the system-level property will be infinite instead of just one point, since they lie on a continuous hyperplane.

\subsection{Alternative Approaches}

   \subsubsection{Optimization}

   \subsubsection{Functional Inversion}
   \label{subsec:funcinvert}


\subsection{Special Cases}

   \subsubsection{Classification}

   \subsubsection{One-to-One Mapping}

\section{Using Reverse Mappings}


\section{Evaluation Criteria}

\subsection{Time Required for Preprocessing}

\subsection{Time Required for Querying}

\subsection{Accuracy of the Reverse Mapping}


\section{Summary}




